{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Third-party imports\n",
    "import gradio as gr\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader, UnstructuredPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Constants\n",
    "MODEL = \"gpt-4o\"\n",
    "DB_NAME = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and ensure OpenAI API key is set\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Ensure the OpenAI API key is loaded into the environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob('knowledge-base-Amir/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'} )\n",
    "    folder_docs= loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'knowledge-base-Amir/publications/CAERS-CF.md', 'doc_type': 'publications'}, page_content=\"# ğŸ“š CAERS-CF: Enhancing Convolutional Autoencoder Recommendations through Collaborative Filtering\\n\\n**Published in**: Knowledge and Information Systems (Springer), 2024  \\n**Authors**: Amirhossein Ghadami, Thomas Tran  \\n**DOI**: [10.1007/s10115-024-02204-5](https://doi.org/10.1007/s10115-024-02204-5)\\n\\n---\\n\\n## ğŸ§  Overview\\n\\n**CAERS-CF** is a **hybrid recommendation system** that combines:\\n- A novel **deep learning-based model (CAERS)** leveraging **convolutional autoencoders**\\n- A **collaborative filtering (CF)** approach based on **singular value decomposition (SVD)**\\n\\nThe model aims to merge content and behavior-based recommendation strategies using **linear regression** to dynamically weigh their outputs, yielding state-of-the-art accuracy on benchmark datasets.\\n\\n---\\n\\n## ğŸ§© Key Contributions\\n\\n1. **CAERS** (Convolutional Autoencoder Recommendation System):  \\n   Captures nonlinear, high-order relationships from users' and items' **content data** via CAE architecture.\\n\\n2. **CAERS-CF** Hybrid Model:  \\n   Integrates CAERS and collaborative filtering predictions using **linear regression**, enhancing performance by learning optimal combination weights.\\n\\n---\\n\\n## ğŸ—ï¸ System Architecture\\n\\n### 1. CAERS Workflow\\n\\n- **Input**: Content data from users (age, occupation, gender) and items (movie title, genre, overview)\\n- **Steps**:\\n  - Feature extraction (e.g., Wikipedia scraping, BERT embeddings)\\n  - Content embedding (categorical and continuous)\\n  - Dot product â†’ user-item interaction matrix\\n  - Pass through **CAE**:\\n    - **Encoder**: Convolution + pooling â†’ compressed representation\\n    - **Decoder**: Transposed convolution + upsampling â†’ predicted ratings\\n\\n### 2. Collaborative Filtering Workflow\\n\\n- Uses **SVD-based matrix factorization**\\n- Learns latent user/item vectors (matrices E and G)\\n- Predicts ratings using dot product \\\\( \\\\hat{R}_2 = EG^T \\\\)\\n\\n### 3. Hybrid Integration\\n\\n- Combines predictions \\\\( \\\\hat{R}_1 \\\\) and \\\\( \\\\hat{R}_2 \\\\) via linear regression:\\n  \\\\[\\n  \\\\hat{R} = W_0 + W_1 \\\\cdot \\\\hat{R}_1 + W_2 \\\\cdot \\\\hat{R}_2\\n  \\\\]\\n- Optimized via **gradient descent** to minimize MSE loss\\n\\n---\\n\\n## ğŸ§ª Experimental Setup\\n\\n- **Datasets**:\\n  - MovieLens 100K\\n  - MovieLens 1M\\n- **Evaluation Metrics**: RMSE, MAE\\n- **Training Details**:\\n  - CAERS optimizer: Adam (lr = 0.01)\\n  - CF optimizer: SGD (lr = 0.01)\\n  - Batch size: 32, Train/Val/Test split: 80/10/10\\n  - Hyperparameter tuning via **grid search**\\n\\n---\\n\\n## ğŸ“Š Results\\n\\n| Dataset         | Model      | RMSE   | MAE   |\\n|----------------|------------|--------|--------|\\n| MovieLens 100K | **CAERS-CF** | **0.8801** | **0.6852** |\\n|                | CAERS      | 0.9218 | 0.7248 |\\n|                | CF         | 0.9439 | 0.7451 |\\n| MovieLens 1M   | **CAERS-CF** | **0.8398** | **0.6540** |\\n|                | CAERS      | 0.8817 | 0.6889 |\\n|                | CF         | 0.8860 | 0.6965 |\\n\\n### ğŸ”¬ Comparison with SOTA\\n\\nCAERS-CF significantly outperforms:\\n- GAP, ECAE, DNNRec, DCN-M, URP-CF-SIM, ExtKNNCF  \\n- Achieves **up to ~9% RMSE/MAE improvement**\\n\\n\\n---\\n\\n## ğŸ“Œ Citation\\n\\n```bibtex\\n@article{ghadami2024caerscf,\\n  title={CAERS-CF: enhancing convolutional autoencoder recommendations through collaborative filtering},\\n  author={Ghadami, Amirhossein and Tran, Thomas},\\n  journal={Knowledge and Information Systems},\\n  volume={66},\\n  number={11},\\n  pages={6717â€“6738},\\n  year={2024},\\n  publisher={Springer}\\n}\"),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/publications/Tavo.md', 'doc_type': 'publications'}, page_content=\"# ğŸ›¡ï¸ TAVo: Tor Application Detection with Voting Critic\\n\\n**Published at**: 36th Canadian Conference on Artificial Intelligence (Canadian AI 2023)  \\n**Authors**: Gautam Vira, Samik Pal, Behdad Mansouri, Amirhossein Ghadami, Paula Branco  \\n**Conference Date**: June 5, 2023  \\n**DOI/URL**: [caiac.pubpub.org/pub/5grrmohq](https://caiac.pubpub.org/pub/5grrmohq)  \\n**License**: [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/)\\n\\n---\\n\\n## ğŸ“„ Abstract\\n\\nWith increasing use and traffic in **The Onion Router (TOR)** network, it's essential to identify and monitor traffic types for performance and security. **TAVo** (Tor Application detection with a Voting-classifier Critic) is a novel two-layer classification framework that:\\n\\n- Detects whether network traffic uses TOR.\\n- Identifies the **type of application** generating TOR traffic.\\n- Uses a **Voting Critic** to handle low-confidence predictions, improving classification performance without compromising efficiency.\\n\\n---\\n\\n## ğŸ§  Methodology\\n\\nTAVo consists of a **two-stage classification architecture**:\\n\\n1. **Stage 1**: Classifies traffic as **TOR vs. Non-TOR**.\\n2. **Stage 2**: Further classifies TOR traffic by **application type** (e.g., browsers, messaging apps, file-sharing services).\\n3. **Voting-Classifier Critic**:\\n   - Activates only when the second layer outputs low-confidence predictions.\\n   - Confirms or corrects predictions by combining multiple classifiers.\\n   - Ensures high precision on difficult samples without heavy computational load.\\n\\n---\\n\\n## ğŸ“Š Results\\n\\n| Metric          | Without Critic | With Critic |\\n|-----------------|----------------|-------------|\\n| **F1 Score**    | 84%            | **91%**     |\\n| **Efficiency**  | High           | High (Critic only used when needed) |\\n\\nTAVo demonstrates strong generalization across diverse traffic patterns while maintaining lightweight inference performance.\\n\\n---\\n\\n## ğŸ—ï¸ Architecture Summary\\n\\n     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\n     â”‚ Packet Capture â”‚\\n     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n            â”‚\\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”\\n    â”‚   Layer 1      â”‚\\n    â”‚ TOR / Non-TOR  â”‚\\n    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n            â”‚\\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”\\n    â”‚   Layer 2      â”‚\\n    â”‚  App Detection â”‚\\n    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n            â”‚  (Low confidence?)\\n       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”\\n       â”‚ Critic  â”‚ <â”€â”€ Voting Ensemble (Meta-classifier)\\n       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\\n\\n---\\n\\n## ğŸŒ Citation\\n\\n```bibtex\\n@inproceedings{ghadami2023tavo,\\n  title={TAVo: Tor Application Detection with Voting Critic},\\n  author={Vira, Gautam and Pal, Samik and Mansouri, Behdad and Ghadami, Amirhossein and Branco, Paula},\\n  booktitle={Proceedings of the 36th Canadian Conference on Artificial Intelligence},\\n  year={2023},\\n  url={https://caiac.pubpub.org/pub/5grrmohq}\\n}\"),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/publications/TriDeepRec.md', 'doc_type': 'publications'}, page_content='# ğŸ“˜ TriDeepRec: A Hybrid Deep Learning Approach to Content- and Behavior-Based Recommendation Systems\\n\\n**Published in**: *User Modeling and User-Adapted Interaction*, 2024  \\n**Authors**: Amirhossein Ghadami, Thomas Tran  \\n**DOI**: [10.1007/s11257-024-09418-w](https://doi.org/10.1007/s11257-024-09418-w)\\n\\n---\\n\\n## ğŸ§  Abstract\\n\\n**TriDeepRec** is a hybrid deep learning recommendation system that combines:\\n- **CAERS**: A convolutional autoencoder-based model for content-based filtering\\n- **NCF**: Neural Collaborative Filtering for behavior-based learning\\n- **MLP**: A multilayer perceptron for fusing both modalities\\n\\nTriDeepRec effectively addresses challenges such as **cold-start** problems and achieves superior prediction accuracy and ranking performance compared to SOTA models.\\n\\n---\\n\\n## ğŸ¯ Key Contributions\\n\\n1. **CAERS**: Learns complex content patterns using convolutional autoencoders.\\n2. **NCF**: Captures nonlinear userâ€“item interactions via neural collaborative filtering.\\n3. **MLP Fusion**: Combines CAERS and NCF outputs for refined prediction.\\n4. Robust handling of **cold-start** scenarios using content data only.\\n\\n---\\n\\n## ğŸ—ï¸ Model Architecture\\n\\n### CAERS (Convolutional Autoencoder)\\n- **Input**: User/item metadata (e.g., age, occupation, movie genres, Wikipedia summaries)\\n- **Encoder**: Conv + pooling layers extract latent features\\n- **Decoder**: Deconv + upsampling layers reconstruct rating predictions\\n- Addresses **cold-start** problem using content alone\\n\\n### NCF (Neural Collaborative Filtering)\\n- **GMF**: Learns linear userâ€“item interactions\\n- **MLP**: Models nonlinear behavior-based interactions\\n- Final NCF score:  \\n  \\\\[\\n  \\\\hat{R}_{NCF} = \\\\alpha \\\\cdot GMF + (1 - \\\\alpha) \\\\cdot MLP\\n  \\\\]\\n\\n### TriDeepRec (Hybrid)\\n- **Fusion**: MLP with concatenated outputs \\\\([R_{CAERS} || R_{NCF}]\\\\)\\n- Learns optimal integration via backpropagation\\n- Objective:  \\n  \\\\[\\n  \\\\text{MSE Loss} = \\\\frac{1}{N} \\\\sum_{i=1}^{N} (R_i - \\\\hat{R}_{Hybrid,i})^2\\n  \\\\]\\n\\n---\\n\\n## ğŸ§ª Experimental Setup\\n\\n- **Datasets**: MovieLens 100K and 1M\\n- **Content Enrichment**: Wikipedia scraping + BERT encoding\\n- **Embeddings**:\\n  - Word2Vec for text\\n  - Custom for categorical and continuous features\\n- **Training**:\\n  - CAERS: 2 conv, 2 pool, 3 deconv layers (ReLU/Sigmoid)\\n  - NCF: 64-dim embeddings, dropout=0.5, 6 epochs\\n  - MLP: 32 neurons, tuned with ReLU & regularization\\n\\n---\\n\\n## ğŸ“Š Results\\n\\n| Dataset        | Model        | RMSE   | MAE    | NDCG@10 |\\n|----------------|--------------|--------|--------|---------|\\n| ML-100K        | TriDeepRec   | 0.8845 | 0.6963 | 0.1489  |\\n|                | CAERS        | 0.9218 | 0.7248 | 0.1430  |\\n|                | GAP          | 0.9379 | 0.7343 | 0.1357  |\\n|                | DCN-M        | 0.9552 | 0.7573 | 0.1449  |\\n| ML-1M          | TriDeepRec   | 0.8099 | 0.6258 | 0.1896  |\\n|                | CAERS        | 0.8817 | 0.6889 | 0.1795  |\\n\\n**Cold-start user performance (RMSE)**:\\n| % New Users | CAERS  | GAP    | DNNRec |\\n|-------------|--------|--------|--------|\\n| 10%         | 1.008  | 1.0248 | 1.1077 |\\n| 20%         | 1.0144 | 1.0377 | 1.1153 |\\n| 30%         | 1.0173 | 1.0383 | 1.1413 |\\n\\n---\\n---\\n\\n## ğŸ§  Citation\\n\\n```bibtex\\n@article{ghadami2024trideeprec,\\n  title={TriDeepRec: A Hybrid Deep Learning Approach to Content- and Behavior-Based Recommendation Systems},\\n  author={Ghadami, Amirhossein and Tran, Thomas},\\n  journal={User Modeling and User-Adapted Interaction},\\n  year={2024},\\n  publisher={Springer},\\n  doi={10.1007/s11257-024-09418-w}\\n}'),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/future_plan/future.md', 'doc_type': 'future_plan'}, page_content='# ğŸŒŸ Amir Ghadami â€” Vision, Goals & Execution Plan\\n\\n> â€œDesigning a life of freedom, impact, and legacyâ€”where family, wealth, and purpose align.â€\\n\\n---\\n\\n## ğŸ¯ Ultimate Life Goals (By Age 40)\\n\\nâœ… **Mission**: Master AI, Build Wealth, Create a Legacy\\n\\n---\\n\\n### ğŸ† Dream Life Snapshot\\n\\n- ğŸ¡ Living in a luxurious mansion\\n- ğŸš˜ Driving a Rolls-Royce\\n- ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦ With wife & four amazing kids\\n- ğŸ¤–ğŸ’° Running global AI businesses while giving back to the world ğŸŒ\\n\\n---\\n\\n### ğŸ”¥ The Big Goals\\n\\n- ğŸ’° **$100 Million Net Worth** â€” Through AI, Automation & Scalable Businesses  \\n- ğŸ’¸ **$2 Million Monthly Passive Income** â€” Investing, Entrepreneurship, and Systems  \\n- â¤ï¸ **Find & Build a Loving Family** â€” Wife + 4 Kids  \\n- ğŸ  **Buy Dream Mansion & Luxury Cars** â€” For Myself & My Parents  \\n- ğŸ›‚ **Secure U.S. Green Card** ğŸ‡ºğŸ‡¸  \\n- ğŸ‡¨ğŸ‡¦ **Canadian Citizenship** â€” For Global Freedom  \\n- ğŸ“ **PhD at a Top 50 Global University** â€” AI Research & Leadership  \\n- ğŸŒ **Donate 10% of My Income to Iranian Charity** â€” To Honor My Roots & Give Back\\n\\n---\\n\\n## ğŸš€ 2025 Goals â€” The Execution Year\\n\\n### ğŸ”¹ ğŸ“ Location Goals\\n\\n- ğŸ‡¨ğŸ‡¦ Obtain **Canadian Permanent Residency (PR)**\\n\\n### ğŸ”¹ ğŸ’¼ Career & Education Goals\\n\\n- ğŸ§  Land a **High-Paying AI Role ($90K+ starting salary)**  \\n- ğŸ“ Get accepted to a **PhD program** (UofT / Waterloo preferred)  \\n- ğŸ§‘\\u200dğŸ« **Find a PhD Supervisor** in AI / ML  \\n\\n### ğŸ”¹ ğŸ’¡ AI Mastery Goals\\n\\n- ğŸ§© Complete the **LAMP-A Learning Plan** (LLMs, Agents, MLOps, AWS)\\n- ğŸš€ Launch or contribute to an **AI-based startup or project**\\n- ğŸ… Earn the **AWS Machine Learning Engineer Certificate**\\n- ğŸ’» Solve **150 LeetCode Problems** to ace interviews\\n\\n### ğŸ”¹ ğŸ’– Personal Growth Goals\\n\\n- â¤ï¸ Build a strong relationship with the **Right Woman**\\n- ğŸ§  **Quit Pn** â€” Mental clarity & discipline reset\\n- âœˆï¸ **Travel somewhere amazing** â€” Create a lifelong memory\\n\\n---\\n\\n## ğŸ“† Monthly Execution Plan\\n\\n- ğŸ—“ï¸ **March 2025** â€” (Tracked Offline)\\n- ğŸ§  Daily routines and progress managed via Notion, calendar & personal dashboards\\n\\n---\\n\\n## ğŸ“š Learning Plan\\n\\n> \"Stacking skills to master AI and deploy it at scale\"\\n\\n### ğŸ”¹ Upcoming Courses\\n\\n1. **LLM Engineering** â€“ 25h  \\n2. **AI Agents & LangChain** â€“ 9h  \\n3. **MLOps Bootcamp (AIOps)** â€“ 36h  \\n4. **AWS ML Engineer Certification** â€“ 23h  \\n5. âœ… Followed by a **hands-on MLOps project**\\n\\n---\\n\\n## ğŸ”¥ Final Words\\n\\n> ğŸ’¡ **Visualize It. Plan It. Execute It.**  \\n> ğŸ”¥ **2025 is YOUR Year. Letâ€™s make it legendary.**\\n\\n---'),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/future_plan/courses.md', 'doc_type': 'future_plan'}, page_content=\"## ğŸ¯ Future Learning Goals\\n\\nTo strengthen my applied machine learning skills and remain current with the evolving AI landscape, I am committed to completing the following advanced courses in 2025:\\n\\n1. **LLM Engineering: Master AI and Large Language Models**\\n   - **Duration:** ~25h 16m  \\n   - **Focus:** Deep dive into large language models (LLMs), including architecture, fine-tuning, deployment strategies, and real-world applications.\\n\\n2. **AI Agents & Automation: Business with LangChain & LLM Apps**\\n   - **Duration:** ~9h 46m  \\n   - **Focus:** Practical implementation of AI agents using LangChain to build automation pipelines for business and operational use cases.\\n\\n3. **MLOps Bootcamp: Mastering AI Operations for Success (AIOps)**\\n   - **Duration:** ~36h 30m  \\n   - **Focus:** Comprehensive guide to deploying, monitoring, and maintaining ML systems with a focus on pipeline automation, CI/CD, and real-world MLOps practices.\\n\\n4. **AWS Certified Machine Learning Engineer - Associate (MLA-C01)**\\n   - **Duration:** ~23h 22m  \\n   - **Focus:** Preparation for AWS's ML Engineer certification with in-depth coverage of AWS ML services, infrastructure, model training, and deployment workflows.\\n\\n---\\n\\n## ğŸš€ Application Plan\\n\\n- **Capstone MLOps Project**: Upon completing the MLOps Bootcamp, I will implement a hands-on end-to-end MLOps project to apply and solidify the skills learned.\\n\\n---\\n\\nğŸ“… **Timeline**: These courses are planned for completion over the next few months as part of my 2025 upskilling strategy.\\n\\n> Lifelong learning is key to staying at the forefront of AI innovation.\"),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/projects/done_projects.md', 'doc_type': 'projects'}, page_content=\"# ğŸ’¡ Amir Ghadami â€” AI Projects Portfolio\\n\\nWelcome to my portfolio of AI-driven projects. Below are five unique tools I've developed that showcase my work in multimodal AI, automation, transcription, summarization, and performance optimization.\\n\\n---\\n\\n## ğŸ–¼ï¸ BrochureGen\\n\\n[ğŸ”— GitHub Repo](https://github.com/AmirGadami/BrochureGen)\\n\\n**BrochureGen** automatically generates visually appealing brochures from raw text using a combination of OpenAI for content refinement and DALLÂ·E for image generation.\\n\\n- ğŸ’¬ Uses GPT-4 for text summarization and layout design.\\n- ğŸ¨ Generates matching images for each brochure section.\\n- ğŸ–¨ï¸ Outputs printable brochures in HTML and PDF formats.\\n- ğŸ› ï¸ Stack: OpenAI, Python, HTML/CSS, WeasyPrint.\\n\\n---\\n\\n## ğŸ§­ VoyageAI\\n\\n[ğŸ”— GitHub Repo](https://github.com/AmirGadami/VoyageAI)\\n\\n**VoyageAI** is a conversational AI travel assistant simulation between two agents: Claude as the customer and GPT as the travel expert.\\n\\n- ğŸŒ GPT-4 & Claude simulate multi-turn dialogues.\\n- ğŸ“¸ Integrates image generation via DALLÂ·E for destinations.\\n- ğŸ¤ Plays responses using text-to-speech (`pydub`).\\n- ğŸ”§ Uses function-calling, tool integration, and agent-based design.\\n\\n---\\n\\n## ğŸ“ EchoMinutes\\n\\n[ğŸ”— GitHub Repo](https://github.com/AmirGadami/EchoMinutes)\\n\\n**EchoMinutes** transcribes and summarizes city council meetings using Whisper and LLMs.\\n\\n- ğŸ™ï¸ Uses OpenAI Whisper to transcribe long meeting audio.\\n- ğŸ§  Summarizes with LLaMA and Phi-3 for structured meeting minutes.\\n- ğŸ“ Converts speech to agenda-based summaries with timestamps.\\n- ğŸ’¼ Ideal for governmental transparency, journalism, or civic tech.\\n\\n---\\n\\n## âš™ï¸ Codaptor\\n\\n[ğŸ”— GitHub Repo](https://github.com/AmirGadami/Codaptor)\\n\\n**Codaptor** converts Python code into high-performance C++ using LLMs.\\n\\n- ğŸ” Supports multi-model conversion: GPT-4, Claude, CodeQwen.\\n- ğŸš€ Includes benchmarking and runtime comparisons.\\n- ğŸŒ Gradio interface for code input, conversion, and execution.\\n- ğŸ§ª Auto-tests C++ output for correctness.\\n\\n---\\n\\n## ğŸ’¬ Ragsomthing\\n\\n[ğŸ”— GitHub Repo](https://github.com/AmirGadami/Ragsomthing)\\n\\n**Ragsomthing** is a Retrieval-Augmented Generation (RAG) chatbot designed for insurance tech (Insurellm).\\n\\n- ğŸ” Uses LangChain, Chroma, and OpenAI for high-accuracy RAG.\\n- ğŸ§  Focused on reducing hallucination and cost.\\n- ğŸ’¡ Includes notebook examples and a full pipeline.\\n- ğŸŒ Simple Gradio-based interface for interaction.\\n\\n---\\n\\n## ğŸ“« Contact\\n\\n- ğŸ”— GitHub: [@AmirGadami](https://github.com/AmirGadami)  \\n- ğŸ“§ Email: [ah.ghadami75@gmail.com](mailto:ah.ghadami75@gmail.com)  \\n- ğŸ”— LinkedIn: [amirhosseinghadami](https://www.linkedin.com/in/amirhosseinghadami)  \\n- ğŸ§  Google Scholar: [Amir Ghadami](https://scholar.google.com/citations?user=B2piFEEAAAAJ&hl=en)\\n\\n---\\n\\n> From generating brochures to translating code and meetings, my goal is to simplify complex tasks using powerful AI tools.\"),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/aboutme/aboutme.md', 'doc_type': 'aboutme'}, page_content='# Amir Ghadami\\n\\nğŸ“ Ottawa, ON, Canada  \\nğŸ“§ [ah.ghadami75@gmail.com](mailto:ah.ghadami75@gmail.com)  \\nğŸ”— [LinkedIn](https://www.linkedin.com/in/amirhosseinghadami) | [Google Scholar](https://scholar.google.com/citations?user=B2piFEEAAAAJ&hl=en) | [GitHub](https://github.com/AmirGadami)\\n\\n---\\n\\n## ğŸ§  About Me\\n\\nIâ€™m a **Machine Learning Engineer** and researcher passionate about building intelligent systems that adapt, learn, and deliver real-world value. My work lies at the intersection of ML research and engineering, with expertise in recommendation systems, large language models, MLOps, and NLP. I enjoy transforming complex problems into scalable, data-driven solutionsâ€”whether in academia, industry, or civic applications.\\n\\n---\\n\\n## ğŸ›  Skills\\n\\n**Languages**: Python, C++, SQL, R  \\n**Libraries & Frameworks**: PyTorch, TensorFlow, scikit-learn, Transformers, NLTK, NumPy, Pandas  \\n**MLOps & Deployment**: MLflow, Docker, Kubernetes, Jenkins, CI/CD, FastAPI, Flask, Streamlit  \\n**Cloud & DevOps**: AWS, Prometheus, Grafana, GitHub Actions, Linux  \\n**Databases**: SQL, NoSQL, MS SQL Server\\n\\n---\\n\\n## ğŸ“ Education\\n\\n**MSc. in Computer Science** â€” *University of Ottawa*  \\n2022 â€“ 2024 | GPA: 3.96/4.0  \\nThesis: *Hybrid Recommendation Systems for Personalized User Experience*\\n\\n**BSc. in Computer Engineering** â€” *Azad Tehran University*  \\n2016 â€“ 2021 | GPA: 3.95/4.0\\n\\n---\\n\\n## ğŸ’¼ Experience\\n\\n**Research Assistant** â€” *University of Ottawa*  \\n*2022 â€“ 2024*  \\n- Researched and developed hybrid recommendation systems using deep learning and NLP  \\n- Applied fine-tuning techniques on large language models for summarization and personalization  \\n- Contributed to academic publications in top-tier journals and conferences  \\n\\n**Data Scientist** â€” *Data Co Lab, Ottawa*  \\n*2020 â€“ 2022*  \\n- Built and deployed predictive models to support business decision-making  \\n- Created robust data pipelines and cleaned complex datasets for machine learning pipelines  \\n- Collaborated with stakeholders to drive strategic insights through data\\n\\n---\\n\\n## ğŸ“„ Publications\\n\\n- **TriDeepRec**: A Hybrid Deep Learning Approach to Content and Behaviour-based Recommendation Systems  \\n  *User Modeling and User-Adapted Interaction, 2024*\\n\\n- **CAERS-CF**: Enhancing Convolutional Autoencoder Recommendations through Collaborative Filtering  \\n  *Knowledge and Information Systems, 2024*\\n\\n- **Conference Paper**: TAVo: Tor Application Detection with Voting Critic\\n  *Canadian AI Conference 2023*  \\n\\n\\n---\\n\\n## ğŸ—£ Languages\\n\\n- English â€“ Fluent  \\n- Persian â€“ Native\\n\\n---\\n\\n## ğŸ§© Interests\\n\\nLLMs, Recommender Systems, Generative AI, Civic Tech, Scalable ML Systems, NLP, Applied Research')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='# ğŸ“š CAERS-CF: Enhancing Convolutional Autoencoder Recommendations through Collaborative Filtering\n",
      "\n",
      "**Published in**: Knowledge and Information Systems (Springer), 2024  \n",
      "**Authors**: Amirhossein Ghadami, Thomas Tran  \n",
      "**DOI**: [10.1007/s10115-024-02204-5](https://doi.org/10.1007/s10115-024-02204-5)\n",
      "\n",
      "---\n",
      "\n",
      "## ğŸ§  Overview\n",
      "\n",
      "**CAERS-CF** is a **hybrid recommendation system** that combines:\n",
      "- A novel **deep learning-based model (CAERS)** leveraging **convolutional autoencoders**\n",
      "- A **collaborative filtering (CF)** approach based on **singular value decomposition (SVD)**\n",
      "\n",
      "The model aims to merge content and behavior-based recommendation strategies using **linear regression** to dynamically weigh their outputs, yielding state-of-the-art accuracy on benchmark datasets.\n",
      "\n",
      "---\n",
      "\n",
      "## ğŸ§© Key Contributions\n",
      "\n",
      "1. **CAERS** (Convolutional Autoencoder Recommendation System):  \n",
      "   Captures nonlinear, high-order relationships from users' and items' **content data** via CAE architecture.' metadata={'source': 'knowledge-base-Amir/publications/CAERS-CF.md', 'doc_type': 'publications'}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vecotrestore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=DB_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecotrestore._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vecotrestore._collection.get(limit=4,include=['embeddings'])['embeddings'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/yz64p8z5579c6d6yx28446qh0000gn/T/ipykernel_24396/1942501086.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.7,model_name='gpt-4o')\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vecotrestore.as_retriever(search_kwargs={\"k\": 25})\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conversation_chain.invoke({'question':'what are the papers he wrote and the titles and a short explainations'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amir Ghadami has authored the following papers:\n",
      "\n",
      "1. **TriDeepRec: A Hybrid Deep Learning Approach to Content and Behaviour-based Recommendation Systems**\n",
      "   - *Published in*: User Modeling and User-Adapted Interaction, 2024\n",
      "   - *Explanation*: This paper introduces TriDeepRec, a hybrid recommendation system that combines content-based and behavior-based approaches using deep learning. It addresses challenges like cold-start problems and improves prediction accuracy and ranking performance.\n",
      "\n",
      "2. **CAERS-CF: Enhancing Convolutional Autoencoder Recommendations through Collaborative Filtering**\n",
      "   - *Published in*: Knowledge and Information Systems, 2024\n",
      "   - *Explanation*: This paper presents CAERS-CF, a hybrid recommendation system that integrates a convolutional autoencoder with collaborative filtering. It aims to combine content and behavior-based strategies to achieve superior accuracy on benchmark datasets.\n",
      "\n",
      "3. **TAVo: Tor Application Detection with Voting Critic**\n",
      "   - *Published in*: Canadian AI Conference 2023\n",
      "   - *Explanation*: TAVo is a two-layer classification framework for detecting and identifying applications generating TOR traffic. It utilizes a Voting Critic to improve classification performance, especially for low-confidence predictions, without sacrificing efficiency.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amir Ghadami holds a Master of Science (MSc) in Computer Science from the University of Ottawa and a Bachelor of Science (BSc) in Computer Engineering from Azad Tehran University.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke({'question':'what is his degree'})['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat,type='messages').launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
