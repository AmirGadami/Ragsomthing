{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Third-party imports\n",
    "import gradio as gr\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader, UnstructuredPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Constants\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "DB_NAME = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and ensure OpenAI API key is set\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Ensure the OpenAI API key is loaded into the environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob('../knowledge-base-Amir/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading file ../knowledge-base-Amir/publications/s11257-024-09418-w.pdf\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfminer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[135]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      5\u001b[39m md_loader = DirectoryLoader(\n\u001b[32m      6\u001b[39m folder,\n\u001b[32m      7\u001b[39m glob=\u001b[33m\"\u001b[39m\u001b[33m**/*.md\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m loader_cls=TextLoader,\n\u001b[32m      9\u001b[39m loader_kwargs={\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m})   \n\u001b[32m     10\u001b[39m pdf_loader = DirectoryLoader(\n\u001b[32m     11\u001b[39m folder,\n\u001b[32m     12\u001b[39m glob=\u001b[33m\"\u001b[39m\u001b[33m**/*.pdf\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m loader_cls=UnstructuredPDFLoader)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m folder_docs= md_loader.load()+ \u001b[43mpdf_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m folder_docs:\n\u001b[32m     16\u001b[39m     doc.metadata[\u001b[33m\"\u001b[39m\u001b[33mdoc_type\u001b[39m\u001b[33m\"\u001b[39m] = doc_type\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:117\u001b[39m, in \u001b[36mDirectoryLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Document]:\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.lazy_load())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:195\u001b[39m, in \u001b[36mDirectoryLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy_load_file(i, p, pbar)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[32m    198\u001b[39m     pbar.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:233\u001b[39m, in \u001b[36mDirectoryLoader._lazy_load_file\u001b[39m\u001b[34m(self, item, path, pbar)\u001b[39m\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    232\u001b[39m         logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError loading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:223\u001b[39m, in \u001b[36mDirectoryLoader._lazy_load_file\u001b[39m\u001b[34m(self, item, path, pbar)\u001b[39m\n\u001b[32m    221\u001b[39m loader = \u001b[38;5;28mself\u001b[39m.loader_cls(\u001b[38;5;28mstr\u001b[39m(item), **\u001b[38;5;28mself\u001b[39m.loader_kwargs)\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/unstructured.py:107\u001b[39m, in \u001b[36mUnstructuredBaseLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    106\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     elements = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m._post_process_elements(elements)\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33melements\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:92\u001b[39m, in \u001b[36mUnstructuredPDFLoader._get_elements\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m partition_pdf(filename=\u001b[38;5;28mself\u001b[39m.file_path, **\u001b[38;5;28mself\u001b[39m.unstructured_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/unstructured/partition/pdf.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwrapt\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LTContainer, LTImage, LTItem, LTTextBox\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m open_filename\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpi_heif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_heif_opener\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pdfminer'"
     ]
    }
   ],
   "source": [
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'} )\n",
    "    folder_docs= loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../knowledge-base-Amir/future_plan/future.md', 'doc_type': 'future_plan'}, page_content='## 🎯 Ultimate Life Goals (Age 40)\\n\\n**Deadline:** By Age 40\\n\\n“Designing a life of freedom, impact, and legacy—where family, wealth, and purpose align.”\\n\\n✅ **Mission:** Master AI, Build Wealth, Create a Legacy.\\n\\n---\\n\\n## 🏆 Dream Life Snapshot:\\n\\n- 🏡 Living in a luxurious mansion\\n- 🚘 Driving a Rolls-Royce\\n- 👨\\u200d👩\\u200d👧\\u200d👦 With wife & kids\\n- 🤖💰 Running AI businesses while giving back to the world. 🌍\\n\\n---\\n\\n## 🔥 🏆 The Big Goals\\n\\n- 💰 **$100 Million Net Worth** – Building AI & Automation Wealth 🚀\\n- 💸 **$2 Million Monthly Passive Income** – Investing, Business & AI 💡\\n- ❤️ **Find & Build a Loving Family** – Wife + 4 kids 👩\\u200d❤️\\u200d👨👧👦👧👦\\n- 🏠 **Buy Dream Mansion & Luxury Cars** for Parents and Myself 🎁\\n- 🛂 **Secure a U.S. Green Card** 🇺🇸\\n- 🇨🇦 **Canadian Citizenship** – Permanent Global Freedom 🌎\\n- 🏛️ **PhD at a Top 50 University** – AI & Research Leadership 🎓\\n- 🌍 **Donate 10% of Income to Iranian Charity** – Giving Back ❤️\\n\\n---\\n\\n## 🚀 2025 Goals – The Execution Year!\\n\\n### 🔹 📍 Location Goals:\\n\\n- 🇨🇦 **Obtain Canadian PR (Permanent Residency)**\\n\\n### 🔹 💼 Career & Education Goals:\\n\\n- 🏆 **Land a High-Paying AI Job ($90K+ Starting Salary)**\\n- 📖 **PhD at University of Toronto / Waterloo**\\n- 🎓 **Find a PhD Supervisor in AI/ML**\\n\\n### 🔹 💡 AI Mastery Goals:\\n\\n- 🎯 **Complete 3-Month LAMP-A Learning Plan (LLM, Agents, MLOps, AWS)**\\n- 🏗️ **Build an AI Business or Side Project**\\n- 📝 **AWS Machine Learning Engineering Certificate**\\n- 🧑🏽\\u200d💻 **150 Leetcode Interview Questions**\\n\\n### 🔹 💖 Personal Growth Goals:\\n\\n- ❤️ **Find the Right Woman & Build a Relationship**\\n- 🚫 **Quit Pn – Mental & Discipline Reset 🧠**\\n- ✈️ **Take an Epic Travel Adventure 🌍**\\n\\n---\\n\\n## 📆 Monthly Execution Plan\\n\\n- March 2025 Plan (Defined Offline)\\n\\n---\\n\\n💡 **Visualize It. Plan It. Execute It.**\\n\\n🔥 **2025 is YOUR Year. Let’s make it legendary. 🚀🏆**'),\n",
       " Document(metadata={'source': '../knowledge-base-Amir/future_plan/courses.md', 'doc_type': 'future_plan'}, page_content='## 🎯 Course Selection\\n\\n1. **LLM Engineering: Master AI and Large Language Models**\\n    - **Duration:** ~25h 16m\\n    - **Focus:** Understanding large language models (LLMs), their applications, fine-tuning, and deployment.\\n\\n2. **AI Agents & Automation: Business with LangChain & LLM Apps**\\n    - **Duration:** ~9h 46m\\n    - **Focus:** Implementing AI agents and automation in business using LangChain, including real-world applications.\\n\\n3. **MLOps Bootcamp: Mastering AI Operations for Success (AIOps)**\\n    - **Duration:** ~36h 30m\\n    - **Focus:** Best practices for deploying and maintaining machine learning models, including setting up ML pipelines and workflows.\\n\\n4. **AWS Certified Machine Learning Engineer - Associate (MLA-C01)**\\n    - **Duration:** ~23h 22m\\n    - **Focus:** Preparing for the AWS ML Engineer certification, covering AWS services for machine learning and model deployment.\\n\\n---\\n\\n## 🚀 Project\\n\\n- **MLOps Project:** Implement a hands-on project after completing the MLOps course to apply the skills learned.\\n\\n---\\n\\n📅 **Course Timeline:** Managed separately in personal planning tools.'),\n",
       " Document(metadata={'source': '../knowledge-base-Amir/projects/1.md', 'doc_type': 'projects'}, page_content='# 📄 BrochureGen\\n\\nBrochureGen is an AI-powered tool that analyzes company websites and generates a short brochure in markdown format. It extracts relevant information such as company culture, careers, and customer details, making it useful for prospective customers, investors, and recruits.\\n\\n## 🚀 Features\\n- **Website Scraping:** Extracts website content, including title, text, and links.\\n- **AI-Powered Analysis:** Uses OpenAI\\'s API to generate a structured brochure.\\n- **Smart Link Filtering:** Identifies and selects relevant links (e.g., About, Careers pages).\\n- **Streaming Output:** Displays AI-generated content dynamically in the terminal.\\n\\n## 🛠️ Installation\\n\\n### 1️⃣ Clone the Repository\\n```bash\\ngit clone https://github.com/AmirGadami/BrochureGen.git\\ncd BrochureGen\\n```\\n\\n### 2️⃣ Install Dependencies\\n```bash\\nconda env create -f environment.yml\\nconda activate llms\\n```\\n\\n## 🔧 Configuration\\n1. **Set up OpenAI API access:**\\n   - Add your OpenAI API key to a `.env` or `config.py` file.\\n   - Ensure the `MODEL` variable is correctly set.\\n\\n2. **Modify `config.py` (if applicable)**\\n```python\\nMODEL = \"gpt-4o-mini\"  # Adjust the model as needed\\n```\\n\\n## 🏃 Usage\\n\\nRun the script and follow the prompts:\\n```bash\\npython main.py\\n```\\n\\n### Example Input\\n```\\nEnter the company Name: CNN\\nEnter the company Website: cnn.com\\n```\\n\\n### Example Output (Markdown Brochure)\\n```markdown\\n## About Us\\nCNN (Cable News Network) is a leading global news organization, delivering breaking news and in-depth analysis across a multitude of topics including politics, business, health, entertainment, science, and climate. Established with a commitment to journalistic integrity, CNN continues to be at the forefront of the news landscape, providing accurate and timely updates worldwide.\\n\\n## Our Mission\\nAt CNN, our mission is to inform, engage, and empower our audience by presenting the news that matters. We aim to drive conversations and foster understanding of critical issues impacting communities globally.\\n\\n## Company Culture\\nCNN embraces a culture of innovation, collaboration, and respect. We are passionate about our work and believe in the importance of a diverse and inclusive workplace. Our team thrives in an environment where ideas are shared freely, where feedback is encouraged, and where every member\\'s contribution is valued.\\n\\n## Our Customers\\nCNN serves a broad audience across various demographics, delivering news and information tailored to the interests of viewers and readers. Our offerings include live television broadcasts, multimedia content, newsletters, and interactive platforms, ensuring that our audience is well-informed on local, national, and international news.\\n\\n## Careers at CNN\\nJoin us in our mission to inform the world! CNN offers a variety of career opportunities across different fields such as journalism, broadcasting, digital media, technology, and marketing. Whether you are an experienced professional or a passionate newcomer, CNN provides a supportive environment for growth and development. Explore job openings and be part of a company that stands for excellence in news reporting.\\n\\n## Stay Connected\\nFollow CNN on social media or visit our website for the latest updates, subscribe to our newsletters, and engage with our diverse range of content. Your feedback is important to us, and we encourage you to connect with us to help improve your experience.\\n\\n---\\n\\n### Contact Us\\nFor inquiries, feedback, or career opportunities, please visit [CNN Careers](https://jobs.cnn.com).\\n```\\n### Sample Web UI Screenshot\\nHere’s how the web interface looks:\\n\\n![BrochureGen Web UI](sample.png)\\n## 🛠️ Project Structure\\n```\\n📂 BrochureGen\\n├── 📜 main.py          # Main script to generate the brochure\\n├── 📜 llm.py           # AI processing and streaming logic\\n├── 📜 scraper.py       # Website scraping logic\\n├── 📜 config.py        # Configuration settings (e.g., API keys, model selection)\\n├── 📜 environment.yml  # Dependencies\\n├── 📜 README.md        # Project documentation\\n```\\n\\n## 📝 TODO / Future Enhancements\\n- ✅ Improve link selection logic for better relevance.\\n- ✅ Implement multi-page scraping for more detailed brochures.\\n- 🚀 Add support for saving brochures as PDF or HTML.\\n- 🚀 Develop a web-based UI for user interaction.\\n\\n## 📜 License\\nThis project is open-source and available under the [MIT License](LICENSE).\\n\\n## 🤝 Contributing\\nContributions are welcome! Feel free to open an issue or submit a pull request.\\n\\n## 📞 Contact\\nFor questions or suggestions, reach out via [ah.ghadami75@gmail.com](mailto:your-email@example.com).\\n\\n'),\n",
       " Document(metadata={'source': '../knowledge-base-Amir/projects/4.md', 'doc_type': 'projects'}, page_content='# 🌍 VoyageAi\\n\\n**VoyageAi** is an interactive multi-agent system where **Claude** (as a curious traveler) chats with **GPT** (as a travel assistant). Together, they simulate a smart, multimodal travel conversation powered by **images**, **audio**, and dynamic **tool use**.\\n\\n> The name *VoyageAi* reflects the spirit of exploration: \"voyage\" representing travel, and \"AI\" for the intelligent agents navigating the journey.\\n\\n---\\n\\n## ✨ Features\\n\\n### 🤖 Two AI Agents\\n- **Claude** asks detailed travel questions (customer)  \\n- **GPT** responds with assistance, prices, and suggestions (agent)\\n\\n### 🛠️ Tool Calling\\n- GPT uses structured function calling to fetch real-time ticket prices via a custom tool\\n\\n### 🖼️ Image Generation\\n- GPT generates vibrant, pop-art-style travel posters using **DALL·E 3**\\n\\n### 🔊 Text-to-Speech\\n- GPT and Claude \"speak\" using OpenAI\\'s TTS model (voices: Alloy & Onyx)\\n\\n### 💬 Real-Time Chat Interface\\n- Gradio UI shows the conversation streaming line-by-line with chat bubbles and images\\n\\n### 📸 Sample Output\\n\\n![Sample Output](sample.png)\\n\\n---\\n\\n## 📂 Project Structure\\n\\n```\\nvoyageAi/\\n├── app.py               # Main app and Gradio interface\\n├── llm_agents.py        # GPT + Claude logic (tool use, image, audio)\\n├── config.py            # System prompts, model names\\n├── utills.py            # Helper functions (tools, pricing, image handling)\\n├── environment.yml      # Conda environment setup\\n├── README.md            # Project documentation\\n├── sample.png           # Sample generated output\\n└── notebook/            # Experimental notebooks and scratchpad\\n```\\n\\n---\\n\\n## 🚀 Getting Started\\n\\n### 1. Clone the Repo\\n```bash\\ngit clone https://github.com/amirgadami/voyageAi.git\\ncd voyageAi\\n```\\n\\n### 2. Set Up the Environment\\n```bash\\nconda env create -f environment.yml\\nconda activate lmms\\n```\\n\\n### 3. Add API Keys\\nCreate a `.env` file:\\n```\\nOPENAI_API_KEY=your_openai_key\\nANTHROPIC_API_KEY=your_anthropic_key\\n```\\n\\n### 4. Run the App\\n```bash\\npython app.py\\n```\\n\\n---\\n\\n## 🤝 Contributing\\n\\nContributions are welcome! Feel free to fork the repo, submit a pull request, or open an issue for any improvements or ideas.\\n\\nSome fun directions to explore:\\n- ✈️ User-controlled Claude input\\n- 🛫 Travel itinerary generator\\n- 🖼️ Image gallery per conversation\\n- 📁 Chat transcript exporter (Markdown or PDF)\\n\\n---\\n\\n## 📢 Contact\\n\\nMade with ❤️ by **Amir Ghadami**\\n\\nFor feedback, ideas, or collaboration, feel free to reach out:\\n\\n- 📧 **Email**: ah.ghadami75@gmail.com  \\n- 🔗 **LinkedIn**: [Amirhossein Ghadami](https://www.linkedin.com/in/amirhosseinghadami/)  \\n- 🕊️ **Twitter (X)**: [@Amir_ghadamii](https://x.com/Amir_ghadamii)\\n\\n---\\n\\n## 🧪 License\\n\\nThis project is licensed under the MIT License. See the `LICENSE` file for more info.'),\n",
       " Document(metadata={'source': '../knowledge-base-Amir/projects/3.md', 'doc_type': 'projects'}, page_content='# 🗣️📋 EchoMinutes\\n\\n**EchoMinutes** is an AI-powered tool that transcribes and summarizes audio recordings from city council and public meetings into structured, readable meeting minutes. It uses OpenAI Whisper for transcription and a quantized LLM (Phi-3 or LLaMA) for summarization.\\n\\n🪪 The name EchoMinutes reflects the idea of \"echoing\" the spoken word into official written records.\\n\\n## ✨ Features\\n\\n### 🎙️ Audio Transcription\\n- Uses OpenAI Whisper to convert `.mp3` and `.wav` audio files into accurate text.\\n\\n### 🧠 Summarization with LLMs\\n- Transcripts are summarized into clean, structured meeting minutes in Markdown.\\n- Includes summaries, discussion points, takeaways, and action items with owners.\\n\\n### 🧮 Efficient 4-bit LLM Inference\\n- Uses BitsAndBytes 4-bit quantization to run powerful models with less GPU.\\n- Supports LLaMA 3.1 and Phi-3 Mini.\\n\\n### 📓 Notebook Interface\\n- Full Jupyter/Colab notebook available: `EchoMinutes_Demo.ipynb`\\n- Runs the entire pipeline end-to-end with visual Markdown output.\\n\\n## 📂 Project Structure\\n\\n```\\nEchoMinutes/\\n├── app.py                   # Optional Gradio UI (not required)\\n├── config.py                # Constants and model names\\n├── echo_minutes.py          # Transcribe + summarize logic\\n├── EchoMinutes_Demo.ipynb   # ✅ Full notebook pipeline\\n├── requirements.txt         # Pip dependencies\\n├── sample_audio/            # Example meeting audio files\\n└── README.md\\n```\\n\\n## 🚀 Getting Started\\n\\n### 1. Clone the Repo\\n```bash\\ngit clone https://github.com/amirgadami/EchoMinutes.git\\ncd EchoMinutes\\n```\\n\\n### 2. Set Up the Environment\\n```bash\\nconda env create -f echo_minutes.yml\\nconda activate echo_minutes\\n```\\n\\n### 3. Add API Keys\\nCreate a `.env` file or set environment variables:\\n```bash\\nOPENAI_API_KEY=your_openai_key\\nHF_TOKEN=your_huggingface_token\\n```\\n\\n### 4. Run the Notebook\\n```bash\\njupyter notebook EchoMinutes_Demo.ipynb\\n```\\n\\n## 📋 Sample Output\\n\\n![Sample Output](sample.png)\\n\\n\\n\\n## 🤝 Contributing\\n\\nContributions welcome! Some ideas to explore:\\n\\n- 🗣️ Speaker attribution via diarization\\n- ⏱️ Timestamped action item extraction\\n- 🔁 Support YouTube or live-streamed audio\\n- 🧾 Export minutes to PDF or DOCX\\n\\n## 📢 Contact\\n\\nMade with ❤️ by Amir Ghadami\\n\\n📧 Email: ah.ghadami75@gmail.com  \\n🔗 LinkedIn: [Amirhossein Ghadami](https://www.linkedin.com/in/amirhosseinghadami/)  \\n🕊️ Twitter (X): [@Amir_ghadamii](https://x.com/Amir_ghadamii)\\n\\n## 🧪 License\\n\\nThis project is licensed under the MIT License. See the LICENSE file for more info.\\n'),\n",
       " Document(metadata={'source': '../knowledge-base-Amir/projects/2.md', 'doc_type': 'projects'}, page_content='# ⚡ Codaptor\\n\\n**Codaptor** is an AI-powered code transpiler that converts Python code into high-performance C++ using advanced LLMs like GPT-4, Claude, and CodeQwen. Designed with performance, portability, and clarity in mind, Codaptor brings intelligent language transformation to your fingertips.\\n\\n> 🔁 The name *Codaptor* merges “Code” and “Adaptor” — a system that intelligently adapts one language to another for optimized execution.\\n\\n---\\n\\n## ✨ Features\\n\\n### 🤖 LLM-Powered Transpilation\\n- Seamless code transformation using:\\n  - GPT-4\\n  - Claude\\n\\n\\n### ⚙️ Multi-Model Support\\n- Switch between models with a simple dropdown\\n- Streamed, real-time code generation\\n\\n### 🧠 Performance-Oriented\\n- C++ output optimized for speed and precision\\n- Designed to match output behavior exactly from Python\\n\\n### 🧪 Runtime Execution\\n- Compile and execute both Python and C++ directly in the app\\n- Smart compiler detection across Windows, Linux, and macOS\\n\\n### 💻 Clean Gradio Interface\\n- Fully interactive, responsive UI\\n- Syntax-highlighted code display\\n- 3D-themed buttons and modern UX\\n\\n---\\n\\n## 📂 Project Structure\\n\\n```\\ncodaptor/\\n├── app.py               # Gradio interface and main app launcher\\n├── llms.py              # LLM model integration: GPT, Claude, CodeQwen\\n├── config.py            # Prompts, model names, endpoints, constants\\n├── utills.py            # Helper functions: compiler detection, execution, file I/O\\n├── environment.yml      # Conda environment setup\\n├── .env                 # API keys for OpenAI, Anthropic, HuggingFace\\n└── README.md            # Project documentation\\n```\\n\\n---\\n\\n## 🚀 Getting Started\\n\\n### 1. Clone the Repo\\n```bash\\ngit clone https://github.com/amirgadami/codaptor.git\\ncd codaptor\\n```\\n\\n### 2. Set Up the Environment\\n```bash\\nconda env create -f environment.yml\\nconda llms\\n```\\n\\n### 3. Add API Keys\\nCreate a `.env` file in the root directory:\\n```\\nOPENAI_API_KEY=your_openai_key\\nANTHROPIC_API_KEY=your_anthropic_key\\n```\\n\\n### 4. Run the App\\n```bash\\npython app.py\\n```\\n\\n---\\n### 📸 Sample Output\\n\\n![Sample Output](sample.png)\\n\\n---\\n\\n## 🤝 Contributing\\n\\nContributions are welcome! Feel free to:\\n- 🧠 Add new models or endpoints\\n- 📜 Improve prompt engineering\\n- 🧪 Add more runtime benchmarks\\n- 💡 Suggest features via issues or pull requests\\n\\n---\\n\\n## 📢 Contact\\n\\nMade with 💙 by **Amir Ghadami**\\n\\n- 📧 **Email**: ah.ghadami75@gmail.com\\n- 🔗 **LinkedIn**: [Amirhossein Ghadami](https://www.linkedin.com/in/amirhosseinghadami/)\\n- 🐦 **Twitter (X)**: [@Amir_ghadamii](https://x.com/Amir_ghadamii)\\n\\n---\\n\\n## 🪪 License\\n\\nThis project is licensed under the MIT License. See the `LICENSE` file for more details.\\n'),\n",
       " Document(metadata={'source': '../knowledge-base-Amir/aboutme/aboutme.md', 'doc_type': 'aboutme'}, page_content=\"# 👋 Hi, I'm Amir Ghadami\\n\\n🎓 Machine Learning Engineer | Researcher | AI Developer  \\n📍 Based in Canada | Open to full-time opportunities\\n\\n---\\n\\n## 🚀 About Me\\n\\nI'm a passionate Machine Learning Engineer with a Master's in Computer Science from the University of Ottawa. I specialize in building intelligent systems that combine research-grade AI with production-level robustness. My mission is to bring cutting-edge machine learning ideas to life through efficient, scalable, and impactful engineering.\\n\\nWith a strong foundation in Deep Learning, MLOps, and NLP, I've built several advanced AI projects—ranging from multi-agent systems and conversational AIs to audio-to-text summarization tools and code optimization assistants. I also have a solid publication record in user modeling, recommendation systems, and intelligent agents.\\n\\n---\\n\\n## 🧠 Research & Publications\\n\\n📄 **Journal Articles**\\n- _User Modeling and User-Adapted Interaction_\\n- _Knowledge and Information Systems 66 (11), 6717-6738_\\n\\n📄 **Conference Paper**\\n- _Canadian AI Conference 2023_\\n\\n🔗 [Google Scholar](https://scholar.google.ca/citations?user=B2piFEEAAAAJ&hl=en&oi=ao)\\n\\n---\\n\\n## 💼 Projects\\n\\n- **⚙️ CAERS** – Deep learning content-based recommendation system using convolutional autoencoders.\\n- **🧠 EchoMinutes** – Transcribes and summarizes city council meeting audio using Whisper and LLMs.\\n- **🤖 VoyageAI** – A multi-agent conversational assistant integrating GPT, Claude, DALL·E, and tool calling.\\n- **🛠️ Codaptor** – Translates Python code into optimized C++ using LLMs, with execution & benchmarking.\\n- **📊 Insurellm RAG Bot** – A high-accuracy, low-cost chatbot for Insurance Tech using LangChain, Chroma, and OpenAI.\\n\\n---\\n\\n## 📚 Currently Learning\\n\\n- ✅ AWS Machine Learning Specialty (certification in progress)\\n- ✅ LangChain, MLOps best practices, and Agentic Workflow Design\\n- ✅ Solving 150+ LeetCode problems for deep algorithmic fluency\\n\\n---\\n\\n## 🧰 Tech Stack\\n\\n**Languages**: Python, C++, SQL, JavaScript  \\n**ML Frameworks**: PyTorch, TensorFlow, Hugging Face, OpenAI, LangChain  \\n**Tools**: Docker, MLflow, Git, FastAPI, Gradio, Weights & Biases, ChromaDB  \\n**DevOps**: AWS, GCP, CI/CD, GitHub Actions  \\n**Others**: Streamlit, Pydantic, Whisper, DALL·E, Claude, GPT-4, Anthropic\\n\\n---\\n\\n## 📬 Get in Touch\\n\\n- 📧 Email: ah.ghadami75@gmail.com  \\n- 🔗 [LinkedIn](https://www.linkedin.com/in/amirhosseinghadami/)  \\n- 🐦 [Twitter (X)](https://x.com/Amir_ghadamii)  \\n- 💻 [GitHub](https://github.com/amirgadami)\\n\\n---\\n\\n_“Engineering intelligence that matters.”_\")]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[124]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vecotrestore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecotrestore._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vecotrestore._collection.get(limit=4,include=['embeddings'])['embeddings'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vecotrestore.as_retriever()\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conversation_chain.invoke({'question':'give me a some bulletpoints about trideeprec'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'m sorry, but there is no information provided about \"Trideeprec\" in the context given. If you have more context or details, I\\'d be happy to help with that.'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avery Lancaster is the Co-Founder & Chief Executive Officer (CEO) of Insurellm, a leading Insurance Tech provider based in San Francisco, California. Avery has a background as a Senior Product Manager at Innovate Insurance Solutions before co-founding Insurellm in 2015. Throughout her career, Avery has demonstrated resilience, adaptability, and innovative leadership strategies that have positioned Insurellm as a key player in the insurance technology landscape.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke({'question':'who is avery'})['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat,type='messages').launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
