{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Third-party imports\n",
    "import gradio as gr\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader, UnstructuredPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Constants\n",
    "MODEL = \"gpt-4o\"\n",
    "DB_NAME = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and ensure OpenAI API key is set\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Ensure the OpenAI API key is loaded into the environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob('knowledge-base-Amir/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'} )\n",
    "    folder_docs= loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'knowledge-base-Amir/publications/CAERS-CF.md', 'doc_type': 'publications'}, page_content=\"# 📚 CAERS-CF: Enhancing Convolutional Autoencoder Recommendations through Collaborative Filtering\\n\\n**Published in**: Knowledge and Information Systems (Springer), 2024  \\n**Authors**: Amirhossein Ghadami, Thomas Tran  \\n**DOI**: [10.1007/s10115-024-02204-5](https://doi.org/10.1007/s10115-024-02204-5)\\n\\n---\\n\\n## 🧠 Overview\\n\\n**CAERS-CF** is a **hybrid recommendation system** that combines:\\n- A novel **deep learning-based model (CAERS)** leveraging **convolutional autoencoders**\\n- A **collaborative filtering (CF)** approach based on **singular value decomposition (SVD)**\\n\\nThe model aims to merge content and behavior-based recommendation strategies using **linear regression** to dynamically weigh their outputs, yielding state-of-the-art accuracy on benchmark datasets.\\n\\n---\\n\\n## 🧩 Key Contributions\\n\\n1. **CAERS** (Convolutional Autoencoder Recommendation System):  \\n   Captures nonlinear, high-order relationships from users' and items' **content data** via CAE architecture.\\n\\n2. **CAERS-CF** Hybrid Model:  \\n   Integrates CAERS and collaborative filtering predictions using **linear regression**, enhancing performance by learning optimal combination weights.\\n\\n---\\n\\n## 🏗️ System Architecture\\n\\n### 1. CAERS Workflow\\n\\n- **Input**: Content data from users (age, occupation, gender) and items (movie title, genre, overview)\\n- **Steps**:\\n  - Feature extraction (e.g., Wikipedia scraping, BERT embeddings)\\n  - Content embedding (categorical and continuous)\\n  - Dot product → user-item interaction matrix\\n  - Pass through **CAE**:\\n    - **Encoder**: Convolution + pooling → compressed representation\\n    - **Decoder**: Transposed convolution + upsampling → predicted ratings\\n\\n### 2. Collaborative Filtering Workflow\\n\\n- Uses **SVD-based matrix factorization**\\n- Learns latent user/item vectors (matrices E and G)\\n- Predicts ratings using dot product \\\\( \\\\hat{R}_2 = EG^T \\\\)\\n\\n### 3. Hybrid Integration\\n\\n- Combines predictions \\\\( \\\\hat{R}_1 \\\\) and \\\\( \\\\hat{R}_2 \\\\) via linear regression:\\n  \\\\[\\n  \\\\hat{R} = W_0 + W_1 \\\\cdot \\\\hat{R}_1 + W_2 \\\\cdot \\\\hat{R}_2\\n  \\\\]\\n- Optimized via **gradient descent** to minimize MSE loss\\n\\n---\\n\\n## 🧪 Experimental Setup\\n\\n- **Datasets**:\\n  - MovieLens 100K\\n  - MovieLens 1M\\n- **Evaluation Metrics**: RMSE, MAE\\n- **Training Details**:\\n  - CAERS optimizer: Adam (lr = 0.01)\\n  - CF optimizer: SGD (lr = 0.01)\\n  - Batch size: 32, Train/Val/Test split: 80/10/10\\n  - Hyperparameter tuning via **grid search**\\n\\n---\\n\\n## 📊 Results\\n\\n| Dataset         | Model      | RMSE   | MAE   |\\n|----------------|------------|--------|--------|\\n| MovieLens 100K | **CAERS-CF** | **0.8801** | **0.6852** |\\n|                | CAERS      | 0.9218 | 0.7248 |\\n|                | CF         | 0.9439 | 0.7451 |\\n| MovieLens 1M   | **CAERS-CF** | **0.8398** | **0.6540** |\\n|                | CAERS      | 0.8817 | 0.6889 |\\n|                | CF         | 0.8860 | 0.6965 |\\n\\n### 🔬 Comparison with SOTA\\n\\nCAERS-CF significantly outperforms:\\n- GAP, ECAE, DNNRec, DCN-M, URP-CF-SIM, ExtKNNCF  \\n- Achieves **up to ~9% RMSE/MAE improvement**\\n\\n\\n---\\n\\n## 📌 Citation\\n\\n```bibtex\\n@article{ghadami2024caerscf,\\n  title={CAERS-CF: enhancing convolutional autoencoder recommendations through collaborative filtering},\\n  author={Ghadami, Amirhossein and Tran, Thomas},\\n  journal={Knowledge and Information Systems},\\n  volume={66},\\n  number={11},\\n  pages={6717–6738},\\n  year={2024},\\n  publisher={Springer}\\n}\"),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/publications/Tavo.md', 'doc_type': 'publications'}, page_content=\"# 🛡️ TAVo: Tor Application Detection with Voting Critic\\n\\n**Published at**: 36th Canadian Conference on Artificial Intelligence (Canadian AI 2023)  \\n**Authors**: Gautam Vira, Samik Pal, Behdad Mansouri, Amirhossein Ghadami, Paula Branco  \\n**Conference Date**: June 5, 2023  \\n**DOI/URL**: [caiac.pubpub.org/pub/5grrmohq](https://caiac.pubpub.org/pub/5grrmohq)  \\n**License**: [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/)\\n\\n---\\n\\n## 📄 Abstract\\n\\nWith increasing use and traffic in **The Onion Router (TOR)** network, it's essential to identify and monitor traffic types for performance and security. **TAVo** (Tor Application detection with a Voting-classifier Critic) is a novel two-layer classification framework that:\\n\\n- Detects whether network traffic uses TOR.\\n- Identifies the **type of application** generating TOR traffic.\\n- Uses a **Voting Critic** to handle low-confidence predictions, improving classification performance without compromising efficiency.\\n\\n---\\n\\n## 🧠 Methodology\\n\\nTAVo consists of a **two-stage classification architecture**:\\n\\n1. **Stage 1**: Classifies traffic as **TOR vs. Non-TOR**.\\n2. **Stage 2**: Further classifies TOR traffic by **application type** (e.g., browsers, messaging apps, file-sharing services).\\n3. **Voting-Classifier Critic**:\\n   - Activates only when the second layer outputs low-confidence predictions.\\n   - Confirms or corrects predictions by combining multiple classifiers.\\n   - Ensures high precision on difficult samples without heavy computational load.\\n\\n---\\n\\n## 📊 Results\\n\\n| Metric          | Without Critic | With Critic |\\n|-----------------|----------------|-------------|\\n| **F1 Score**    | 84%            | **91%**     |\\n| **Efficiency**  | High           | High (Critic only used when needed) |\\n\\nTAVo demonstrates strong generalization across diverse traffic patterns while maintaining lightweight inference performance.\\n\\n---\\n\\n## 🏗️ Architecture Summary\\n\\n     ┌────────────────┐\\n     │ Packet Capture │\\n     └──────┬─────────┘\\n            │\\n    ┌───────▼────────┐\\n    │   Layer 1      │\\n    │ TOR / Non-TOR  │\\n    └───────┬────────┘\\n            │\\n    ┌───────▼────────┐\\n    │   Layer 2      │\\n    │  App Detection │\\n    └───────┬────────┘\\n            │  (Low confidence?)\\n       ┌────▼────┐\\n       │ Critic  │ <── Voting Ensemble (Meta-classifier)\\n       └─────────┘\\n\\n\\n---\\n\\n## 🌐 Citation\\n\\n```bibtex\\n@inproceedings{ghadami2023tavo,\\n  title={TAVo: Tor Application Detection with Voting Critic},\\n  author={Vira, Gautam and Pal, Samik and Mansouri, Behdad and Ghadami, Amirhossein and Branco, Paula},\\n  booktitle={Proceedings of the 36th Canadian Conference on Artificial Intelligence},\\n  year={2023},\\n  url={https://caiac.pubpub.org/pub/5grrmohq}\\n}\"),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/publications/TriDeepRec.md', 'doc_type': 'publications'}, page_content='# 📘 TriDeepRec: A Hybrid Deep Learning Approach to Content- and Behavior-Based Recommendation Systems\\n\\n**Published in**: *User Modeling and User-Adapted Interaction*, 2024  \\n**Authors**: Amirhossein Ghadami, Thomas Tran  \\n**DOI**: [10.1007/s11257-024-09418-w](https://doi.org/10.1007/s11257-024-09418-w)\\n\\n---\\n\\n## 🧠 Abstract\\n\\n**TriDeepRec** is a hybrid deep learning recommendation system that combines:\\n- **CAERS**: A convolutional autoencoder-based model for content-based filtering\\n- **NCF**: Neural Collaborative Filtering for behavior-based learning\\n- **MLP**: A multilayer perceptron for fusing both modalities\\n\\nTriDeepRec effectively addresses challenges such as **cold-start** problems and achieves superior prediction accuracy and ranking performance compared to SOTA models.\\n\\n---\\n\\n## 🎯 Key Contributions\\n\\n1. **CAERS**: Learns complex content patterns using convolutional autoencoders.\\n2. **NCF**: Captures nonlinear user–item interactions via neural collaborative filtering.\\n3. **MLP Fusion**: Combines CAERS and NCF outputs for refined prediction.\\n4. Robust handling of **cold-start** scenarios using content data only.\\n\\n---\\n\\n## 🏗️ Model Architecture\\n\\n### CAERS (Convolutional Autoencoder)\\n- **Input**: User/item metadata (e.g., age, occupation, movie genres, Wikipedia summaries)\\n- **Encoder**: Conv + pooling layers extract latent features\\n- **Decoder**: Deconv + upsampling layers reconstruct rating predictions\\n- Addresses **cold-start** problem using content alone\\n\\n### NCF (Neural Collaborative Filtering)\\n- **GMF**: Learns linear user–item interactions\\n- **MLP**: Models nonlinear behavior-based interactions\\n- Final NCF score:  \\n  \\\\[\\n  \\\\hat{R}_{NCF} = \\\\alpha \\\\cdot GMF + (1 - \\\\alpha) \\\\cdot MLP\\n  \\\\]\\n\\n### TriDeepRec (Hybrid)\\n- **Fusion**: MLP with concatenated outputs \\\\([R_{CAERS} || R_{NCF}]\\\\)\\n- Learns optimal integration via backpropagation\\n- Objective:  \\n  \\\\[\\n  \\\\text{MSE Loss} = \\\\frac{1}{N} \\\\sum_{i=1}^{N} (R_i - \\\\hat{R}_{Hybrid,i})^2\\n  \\\\]\\n\\n---\\n\\n## 🧪 Experimental Setup\\n\\n- **Datasets**: MovieLens 100K and 1M\\n- **Content Enrichment**: Wikipedia scraping + BERT encoding\\n- **Embeddings**:\\n  - Word2Vec for text\\n  - Custom for categorical and continuous features\\n- **Training**:\\n  - CAERS: 2 conv, 2 pool, 3 deconv layers (ReLU/Sigmoid)\\n  - NCF: 64-dim embeddings, dropout=0.5, 6 epochs\\n  - MLP: 32 neurons, tuned with ReLU & regularization\\n\\n---\\n\\n## 📊 Results\\n\\n| Dataset        | Model        | RMSE   | MAE    | NDCG@10 |\\n|----------------|--------------|--------|--------|---------|\\n| ML-100K        | TriDeepRec   | 0.8845 | 0.6963 | 0.1489  |\\n|                | CAERS        | 0.9218 | 0.7248 | 0.1430  |\\n|                | GAP          | 0.9379 | 0.7343 | 0.1357  |\\n|                | DCN-M        | 0.9552 | 0.7573 | 0.1449  |\\n| ML-1M          | TriDeepRec   | 0.8099 | 0.6258 | 0.1896  |\\n|                | CAERS        | 0.8817 | 0.6889 | 0.1795  |\\n\\n**Cold-start user performance (RMSE)**:\\n| % New Users | CAERS  | GAP    | DNNRec |\\n|-------------|--------|--------|--------|\\n| 10%         | 1.008  | 1.0248 | 1.1077 |\\n| 20%         | 1.0144 | 1.0377 | 1.1153 |\\n| 30%         | 1.0173 | 1.0383 | 1.1413 |\\n\\n---\\n---\\n\\n## 🧠 Citation\\n\\n```bibtex\\n@article{ghadami2024trideeprec,\\n  title={TriDeepRec: A Hybrid Deep Learning Approach to Content- and Behavior-Based Recommendation Systems},\\n  author={Ghadami, Amirhossein and Tran, Thomas},\\n  journal={User Modeling and User-Adapted Interaction},\\n  year={2024},\\n  publisher={Springer},\\n  doi={10.1007/s11257-024-09418-w}\\n}'),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/future_plan/future.md', 'doc_type': 'future_plan'}, page_content='# 🌟 Amir Ghadami — Vision, Goals & Execution Plan\\n\\n> “Designing a life of freedom, impact, and legacy—where family, wealth, and purpose align.”\\n\\n---\\n\\n## 🎯 Ultimate Life Goals (By Age 40)\\n\\n✅ **Mission**: Master AI, Build Wealth, Create a Legacy\\n\\n---\\n\\n### 🏆 Dream Life Snapshot\\n\\n- 🏡 Living in a luxurious mansion\\n- 🚘 Driving a Rolls-Royce\\n- 👨\\u200d👩\\u200d👧\\u200d👦 With wife & four amazing kids\\n- 🤖💰 Running global AI businesses while giving back to the world 🌍\\n\\n---\\n\\n### 🔥 The Big Goals\\n\\n- 💰 **$100 Million Net Worth** — Through AI, Automation & Scalable Businesses  \\n- 💸 **$2 Million Monthly Passive Income** — Investing, Entrepreneurship, and Systems  \\n- ❤️ **Find & Build a Loving Family** — Wife + 4 Kids  \\n- 🏠 **Buy Dream Mansion & Luxury Cars** — For Myself & My Parents  \\n- 🛂 **Secure U.S. Green Card** 🇺🇸  \\n- 🇨🇦 **Canadian Citizenship** — For Global Freedom  \\n- 🎓 **PhD at a Top 50 Global University** — AI Research & Leadership  \\n- 🌍 **Donate 10% of My Income to Iranian Charity** — To Honor My Roots & Give Back\\n\\n---\\n\\n## 🚀 2025 Goals — The Execution Year\\n\\n### 🔹 📍 Location Goals\\n\\n- 🇨🇦 Obtain **Canadian Permanent Residency (PR)**\\n\\n### 🔹 💼 Career & Education Goals\\n\\n- 🧠 Land a **High-Paying AI Role ($90K+ starting salary)**  \\n- 🎓 Get accepted to a **PhD program** (UofT / Waterloo preferred)  \\n- 🧑\\u200d🏫 **Find a PhD Supervisor** in AI / ML  \\n\\n### 🔹 💡 AI Mastery Goals\\n\\n- 🧩 Complete the **LAMP-A Learning Plan** (LLMs, Agents, MLOps, AWS)\\n- 🚀 Launch or contribute to an **AI-based startup or project**\\n- 🏅 Earn the **AWS Machine Learning Engineer Certificate**\\n- 💻 Solve **150 LeetCode Problems** to ace interviews\\n\\n### 🔹 💖 Personal Growth Goals\\n\\n- ❤️ Build a strong relationship with the **Right Woman**\\n- 🧠 **Quit Pn** — Mental clarity & discipline reset\\n- ✈️ **Travel somewhere amazing** — Create a lifelong memory\\n\\n---\\n\\n## 📆 Monthly Execution Plan\\n\\n- 🗓️ **March 2025** — (Tracked Offline)\\n- 🧠 Daily routines and progress managed via Notion, calendar & personal dashboards\\n\\n---\\n\\n## 📚 Learning Plan\\n\\n> \"Stacking skills to master AI and deploy it at scale\"\\n\\n### 🔹 Upcoming Courses\\n\\n1. **LLM Engineering** – 25h  \\n2. **AI Agents & LangChain** – 9h  \\n3. **MLOps Bootcamp (AIOps)** – 36h  \\n4. **AWS ML Engineer Certification** – 23h  \\n5. ✅ Followed by a **hands-on MLOps project**\\n\\n---\\n\\n## 🔥 Final Words\\n\\n> 💡 **Visualize It. Plan It. Execute It.**  \\n> 🔥 **2025 is YOUR Year. Let’s make it legendary.**\\n\\n---'),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/future_plan/courses.md', 'doc_type': 'future_plan'}, page_content=\"## 🎯 Future Learning Goals\\n\\nTo strengthen my applied machine learning skills and remain current with the evolving AI landscape, I am committed to completing the following advanced courses in 2025:\\n\\n1. **LLM Engineering: Master AI and Large Language Models**\\n   - **Duration:** ~25h 16m  \\n   - **Focus:** Deep dive into large language models (LLMs), including architecture, fine-tuning, deployment strategies, and real-world applications.\\n\\n2. **AI Agents & Automation: Business with LangChain & LLM Apps**\\n   - **Duration:** ~9h 46m  \\n   - **Focus:** Practical implementation of AI agents using LangChain to build automation pipelines for business and operational use cases.\\n\\n3. **MLOps Bootcamp: Mastering AI Operations for Success (AIOps)**\\n   - **Duration:** ~36h 30m  \\n   - **Focus:** Comprehensive guide to deploying, monitoring, and maintaining ML systems with a focus on pipeline automation, CI/CD, and real-world MLOps practices.\\n\\n4. **AWS Certified Machine Learning Engineer - Associate (MLA-C01)**\\n   - **Duration:** ~23h 22m  \\n   - **Focus:** Preparation for AWS's ML Engineer certification with in-depth coverage of AWS ML services, infrastructure, model training, and deployment workflows.\\n\\n---\\n\\n## 🚀 Application Plan\\n\\n- **Capstone MLOps Project**: Upon completing the MLOps Bootcamp, I will implement a hands-on end-to-end MLOps project to apply and solidify the skills learned.\\n\\n---\\n\\n📅 **Timeline**: These courses are planned for completion over the next few months as part of my 2025 upskilling strategy.\\n\\n> Lifelong learning is key to staying at the forefront of AI innovation.\"),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/projects/done_projects.md', 'doc_type': 'projects'}, page_content=\"# 💡 Amir Ghadami — AI Projects Portfolio\\n\\nWelcome to my portfolio of AI-driven projects. Below are five unique tools I've developed that showcase my work in multimodal AI, automation, transcription, summarization, and performance optimization.\\n\\n---\\n\\n## 🖼️ BrochureGen\\n\\n[🔗 GitHub Repo](https://github.com/AmirGadami/BrochureGen)\\n\\n**BrochureGen** automatically generates visually appealing brochures from raw text using a combination of OpenAI for content refinement and DALL·E for image generation.\\n\\n- 💬 Uses GPT-4 for text summarization and layout design.\\n- 🎨 Generates matching images for each brochure section.\\n- 🖨️ Outputs printable brochures in HTML and PDF formats.\\n- 🛠️ Stack: OpenAI, Python, HTML/CSS, WeasyPrint.\\n\\n---\\n\\n## 🧭 VoyageAI\\n\\n[🔗 GitHub Repo](https://github.com/AmirGadami/VoyageAI)\\n\\n**VoyageAI** is a conversational AI travel assistant simulation between two agents: Claude as the customer and GPT as the travel expert.\\n\\n- 🌍 GPT-4 & Claude simulate multi-turn dialogues.\\n- 📸 Integrates image generation via DALL·E for destinations.\\n- 🎤 Plays responses using text-to-speech (`pydub`).\\n- 🔧 Uses function-calling, tool integration, and agent-based design.\\n\\n---\\n\\n## 📝 EchoMinutes\\n\\n[🔗 GitHub Repo](https://github.com/AmirGadami/EchoMinutes)\\n\\n**EchoMinutes** transcribes and summarizes city council meetings using Whisper and LLMs.\\n\\n- 🎙️ Uses OpenAI Whisper to transcribe long meeting audio.\\n- 🧠 Summarizes with LLaMA and Phi-3 for structured meeting minutes.\\n- 📎 Converts speech to agenda-based summaries with timestamps.\\n- 💼 Ideal for governmental transparency, journalism, or civic tech.\\n\\n---\\n\\n## ⚙️ Codaptor\\n\\n[🔗 GitHub Repo](https://github.com/AmirGadami/Codaptor)\\n\\n**Codaptor** converts Python code into high-performance C++ using LLMs.\\n\\n- 🔁 Supports multi-model conversion: GPT-4, Claude, CodeQwen.\\n- 🚀 Includes benchmarking and runtime comparisons.\\n- 🌐 Gradio interface for code input, conversion, and execution.\\n- 🧪 Auto-tests C++ output for correctness.\\n\\n---\\n\\n## 💬 Ragsomthing\\n\\n[🔗 GitHub Repo](https://github.com/AmirGadami/Ragsomthing)\\n\\n**Ragsomthing** is a Retrieval-Augmented Generation (RAG) chatbot designed for insurance tech (Insurellm).\\n\\n- 🔍 Uses LangChain, Chroma, and OpenAI for high-accuracy RAG.\\n- 🧠 Focused on reducing hallucination and cost.\\n- 💡 Includes notebook examples and a full pipeline.\\n- 🌐 Simple Gradio-based interface for interaction.\\n\\n---\\n\\n## 📫 Contact\\n\\n- 🔗 GitHub: [@AmirGadami](https://github.com/AmirGadami)  \\n- 📧 Email: [ah.ghadami75@gmail.com](mailto:ah.ghadami75@gmail.com)  \\n- 🔗 LinkedIn: [amirhosseinghadami](https://www.linkedin.com/in/amirhosseinghadami)  \\n- 🧠 Google Scholar: [Amir Ghadami](https://scholar.google.com/citations?user=B2piFEEAAAAJ&hl=en)\\n\\n---\\n\\n> From generating brochures to translating code and meetings, my goal is to simplify complex tasks using powerful AI tools.\"),\n",
       " Document(metadata={'source': 'knowledge-base-Amir/aboutme/aboutme.md', 'doc_type': 'aboutme'}, page_content='# Amir Ghadami\\n\\n📍 Ottawa, ON, Canada  \\n📧 [ah.ghadami75@gmail.com](mailto:ah.ghadami75@gmail.com)  \\n🔗 [LinkedIn](https://www.linkedin.com/in/amirhosseinghadami) | [Google Scholar](https://scholar.google.com/citations?user=B2piFEEAAAAJ&hl=en) | [GitHub](https://github.com/AmirGadami)\\n\\n---\\n\\n## 🧠 About Me\\n\\nI’m a **Machine Learning Engineer** and researcher passionate about building intelligent systems that adapt, learn, and deliver real-world value. My work lies at the intersection of ML research and engineering, with expertise in recommendation systems, large language models, MLOps, and NLP. I enjoy transforming complex problems into scalable, data-driven solutions—whether in academia, industry, or civic applications.\\n\\n---\\n\\n## 🛠 Skills\\n\\n**Languages**: Python, C++, SQL, R  \\n**Libraries & Frameworks**: PyTorch, TensorFlow, scikit-learn, Transformers, NLTK, NumPy, Pandas  \\n**MLOps & Deployment**: MLflow, Docker, Kubernetes, Jenkins, CI/CD, FastAPI, Flask, Streamlit  \\n**Cloud & DevOps**: AWS, Prometheus, Grafana, GitHub Actions, Linux  \\n**Databases**: SQL, NoSQL, MS SQL Server\\n\\n---\\n\\n## 🎓 Education\\n\\n**MSc. in Computer Science** — *University of Ottawa*  \\n2022 – 2024 | GPA: 3.96/4.0  \\nThesis: *Hybrid Recommendation Systems for Personalized User Experience*\\n\\n**BSc. in Computer Engineering** — *Azad Tehran University*  \\n2016 – 2021 | GPA: 3.95/4.0\\n\\n---\\n\\n## 💼 Experience\\n\\n**Research Assistant** — *University of Ottawa*  \\n*2022 – 2024*  \\n- Researched and developed hybrid recommendation systems using deep learning and NLP  \\n- Applied fine-tuning techniques on large language models for summarization and personalization  \\n- Contributed to academic publications in top-tier journals and conferences  \\n\\n**Data Scientist** — *Data Co Lab, Ottawa*  \\n*2020 – 2022*  \\n- Built and deployed predictive models to support business decision-making  \\n- Created robust data pipelines and cleaned complex datasets for machine learning pipelines  \\n- Collaborated with stakeholders to drive strategic insights through data\\n\\n---\\n\\n## 📄 Publications\\n\\n- **TriDeepRec**: A Hybrid Deep Learning Approach to Content and Behaviour-based Recommendation Systems  \\n  *User Modeling and User-Adapted Interaction, 2024*\\n\\n- **CAERS-CF**: Enhancing Convolutional Autoencoder Recommendations through Collaborative Filtering  \\n  *Knowledge and Information Systems, 2024*\\n\\n- **Conference Paper**: TAVo: Tor Application Detection with Voting Critic\\n  *Canadian AI Conference 2023*  \\n\\n\\n---\\n\\n## 🗣 Languages\\n\\n- English – Fluent  \\n- Persian – Native\\n\\n---\\n\\n## 🧩 Interests\\n\\nLLMs, Recommender Systems, Generative AI, Civic Tech, Scalable ML Systems, NLP, Applied Research')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='# 📚 CAERS-CF: Enhancing Convolutional Autoencoder Recommendations through Collaborative Filtering\n",
      "\n",
      "**Published in**: Knowledge and Information Systems (Springer), 2024  \n",
      "**Authors**: Amirhossein Ghadami, Thomas Tran  \n",
      "**DOI**: [10.1007/s10115-024-02204-5](https://doi.org/10.1007/s10115-024-02204-5)\n",
      "\n",
      "---\n",
      "\n",
      "## 🧠 Overview\n",
      "\n",
      "**CAERS-CF** is a **hybrid recommendation system** that combines:\n",
      "- A novel **deep learning-based model (CAERS)** leveraging **convolutional autoencoders**\n",
      "- A **collaborative filtering (CF)** approach based on **singular value decomposition (SVD)**\n",
      "\n",
      "The model aims to merge content and behavior-based recommendation strategies using **linear regression** to dynamically weigh their outputs, yielding state-of-the-art accuracy on benchmark datasets.\n",
      "\n",
      "---\n",
      "\n",
      "## 🧩 Key Contributions\n",
      "\n",
      "1. **CAERS** (Convolutional Autoencoder Recommendation System):  \n",
      "   Captures nonlinear, high-order relationships from users' and items' **content data** via CAE architecture.' metadata={'source': 'knowledge-base-Amir/publications/CAERS-CF.md', 'doc_type': 'publications'}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vecotrestore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=DB_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecotrestore._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vecotrestore._collection.get(limit=4,include=['embeddings'])['embeddings'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/yz64p8z5579c6d6yx28446qh0000gn/T/ipykernel_24396/1942501086.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.7,model_name='gpt-4o')\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vecotrestore.as_retriever(search_kwargs={\"k\": 25})\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conversation_chain.invoke({'question':'what are the papers he wrote and the titles and a short explainations'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amir Ghadami has authored the following papers:\n",
      "\n",
      "1. **TriDeepRec: A Hybrid Deep Learning Approach to Content and Behaviour-based Recommendation Systems**\n",
      "   - *Published in*: User Modeling and User-Adapted Interaction, 2024\n",
      "   - *Explanation*: This paper introduces TriDeepRec, a hybrid recommendation system that combines content-based and behavior-based approaches using deep learning. It addresses challenges like cold-start problems and improves prediction accuracy and ranking performance.\n",
      "\n",
      "2. **CAERS-CF: Enhancing Convolutional Autoencoder Recommendations through Collaborative Filtering**\n",
      "   - *Published in*: Knowledge and Information Systems, 2024\n",
      "   - *Explanation*: This paper presents CAERS-CF, a hybrid recommendation system that integrates a convolutional autoencoder with collaborative filtering. It aims to combine content and behavior-based strategies to achieve superior accuracy on benchmark datasets.\n",
      "\n",
      "3. **TAVo: Tor Application Detection with Voting Critic**\n",
      "   - *Published in*: Canadian AI Conference 2023\n",
      "   - *Explanation*: TAVo is a two-layer classification framework for detecting and identifying applications generating TOR traffic. It utilizes a Voting Critic to improve classification performance, especially for low-confidence predictions, without sacrificing efficiency.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amir Ghadami holds a Master of Science (MSc) in Computer Science from the University of Ottawa and a Bachelor of Science (BSc) in Computer Engineering from Azad Tehran University.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke({'question':'what is his degree'})['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat,type='messages').launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
